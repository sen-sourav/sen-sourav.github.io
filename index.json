[{"authors":["admin"],"categories":null,"content":"I am a Ph.D. student in Experimental Particle Physics at Duke University. My research involves writing code and analyzing data from sub-atomic particle collisions at very high energies. I am also very interested in machine learning. In my spare time, I like reading about ML algorithms and also applying them, even beyond my physics research, in some of my pet projects.\nI currently work in the ATLAS experiment of the Large Hadron Collider (LHC). For my thesis project, I analyze data to search for a production process of the Higgs boson, known as the vector boson fusion (VBF) process, from the proton-proton collisions. I am also part of the analysis team looking for BSM motivated new particle decaying into top quarks. In the past, I have also worked on the design of the proposed Future Circular Hadron Collider (FCC-hh). I am also one of the analyzers in the team, measuring the most precise mass of the W boson from the Collider Detector at Fermilab proton-antiproton collision data.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":-62135596800,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://sen-sourav.github.io/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/admin/","section":"authors","summary":"I am a Ph.D. student in Experimental Particle Physics at Duke University. My research involves writing code and analyzing data from sub-atomic particle collisions at very high energies. I am also very interested in machine learning. In my spare time, I like reading about ML algorithms and also applying them, even beyond my physics research, in some of my pet projects.\nI currently work in the ATLAS experiment of the Large Hadron Collider (LHC).","tags":null,"title":"Sourav Sen","type":"authors"},{"authors":[],"categories":[],"content":" %%HTML \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; table.dataframe td, table.dataframe th { border: 1px black solid !important; color: black !important; } \u0026lt;/style\u0026gt;  table.dataframe td, table.dataframe th { border: 1px black solid !important; color: black !important; }  As an experimental High Energy Physics (hep-ex) grad student, I often wonder which university/national lab should I choose for doing a postdoc to increase my odds of getting a faculty position, if I plan to stay in academia. But unlike other sub-fields in Physics, we have huge world-wide collaborations for hep-ex experiments like the Large Hadron Collider. In such collaborative environment, it is not very clear if it really matters where one does his/her postdoc, in terms of finding an academic faculty (research scientist) position. It might not be hard to convince oneself that there is actually no such correlation between a postdoc\u0026rsquo;s affiliation and possibility of finding an academic job (faculty position) eventually. This has prompted me to put this hypothesis to test. So, let\u0026rsquo;s explore here whether such a correlation between a postdoc\u0026rsquo;s affiliation and future success in finding an academic faculty position in hep-ex exists.\nimport re import pandas as pd import numpy as np import matplotlib.pyplot as plt %matplotlib inline from sklearn.linear_model import LogisticRegression  Data collection hepexrumor (https://sites.google.com/site/hepexrumor/) is a popular unofficial site which has latest rumors about the hep-ex jobs (in the US and ouside). I parse this website for getting the job rumors from 2005-2019. For this short study, I did not consider temporal variation in job patterns and combined the data of all the years.\nI use the latest affiliation of a postdoc while applying for job. I only consider the postdocs who cleared the short-list round for a job as the total candidate pool, with a presumptuous assumption that postdocs not clearing the shortlist were not serious candidates for the job.\nParsing hepexrumor:\nhepexjobsite = 'https://sites.google.com/site/hepexrumor/' year = {2005: '2005-rumor' , 2006: '2006-rumor' , 2007: '2007-rumor' , 2008: '2008-rumor' , 2009: '2009-rumor-1', 2010: '2009-rumor' , 2011: '2011-rumors' , 2012: '2012-rumors' , 2013: '2013-rumors' , 2014: '2014-rumors' , 2015: '2015-rumors' , 2016: '2016-rumors' , 2017: '2016-2017' , 2018: '2018-rumors' , 2019: '2019-rumors' } df = {} for i in range(2005,2020): p = pd.read_html(hepexjobsite+year[i]) print(i, len(p)) if (i \u0026lt; 2016 ): tUS = p[3].iloc[1:] tUS.columns = p[3].iloc[0] else: tnonUS = p[4].iloc[1:] tnonUS.columns = p[4].iloc[0] tnonUS = tnonUS.drop(columns=['Field']) tUS = p[5].iloc[1:] tUS.columns = p[5].iloc[0] tUS = tUS.drop(columns=['Field']) tUS.append(tnonUS, ignore_index=True) tUS.columns = [\u0026quot;Institution\u0026quot;, \u0026quot;Short List\u0026quot;, \u0026quot;Offers\u0026quot;] df[i] = tUS  2005 4 2006 4 2007 4 2008 4 2009 4 2010 4 2011 4 2012 4 2013 4 2014 4 2015 4 2016 6 2017 6 2018 6 2019 6  df[2017].head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Institution Short List Offers     1 Nebraska Jamie Antonelli (Ohio State) [CMS] Clemens Lan... Frank Golf (accepted)   2 Wilson Fellowship Joseph Zennamo (Chicago) [MicroBooNE, SBND] Mi... Minerba Betancourt (accepted) Nhan Tran (accep...   3 Alabama Carl Pfendner (Ohio State) [ARA, EVA] NaN   4 Cornell (accelerators) NaN NaN   5 Brookhaven John Alison (Chicago) [ATLAS] Viviana Cavalier... Viviana Cavaliere (accepted)     Data cleaning There is ambiguity associated to the names of some of the universities and labs, like Fermilab is listed as \u0026lsquo;Fermilab\u0026rsquo; in some places and \u0026lsquo;FNAL\u0026rsquo; elsewhere. The function below removes this ambiguity by replacing the ambiguous names to a standard name for the organizations:\ndef UniNameAmbiguityFix(dfk): Uni_name_ambiguity = {'Argonne': 'ANL', 'Boston University': 'Boston U', 'BU': 'Boston U', 'Brown University': 'Brown', 'Cal Tech': 'Caltech', 'Carnegie': 'Carnegie Mellon', 'Colorado State University': 'Colorado State', 'Fermilab': 'FNAL', 'FNAL/Chicago': 'FNAL', 'Industry/Fermilab': 'FNAL', 'Chicago/FNAL': 'FNAL', 'Göttingen': 'Gottingen', 'Imperial': 'Imperial College London', 'Indiana': 'Indiana University', 'KSU': 'Kansas State', 'Los Alamos': 'LANL', 'LBL': 'LBNL', 'MSU': 'Michigan State', 'Northeastern University': 'Northeastern', 'Northwestern University': 'Northwestern', 'OSU': 'Ohio State', 'SUNY Stony Brook': 'Stony Brook', 'Texas A\u0026amp;M': 'TAMU', 'Triumf': 'TRIUMF', 'U Chicago': 'UChicago', 'Chicago': 'UChicago', 'University of Chicago': 'UChicago', 'Berkeley': 'UC Berkeley', 'University of Colorado Boulder': 'UC Boulder', 'CU Boulder': 'UC Boulder', 'Colorado': 'UC Boulder', 'Davis': 'UC Davis', 'Irvine': 'UC Irvine', 'UCSD': 'UC San Diego', 'UCSB': 'UC Santa Barbara', 'UCSC': 'UC Santa Cruz', 'UIC': 'University of Illinois Chicago', 'University of Illinois Urbana-Champaign': 'UIUC', 'University of North Carolina': 'UNC', 'University of Pennsylvania': 'UPenn', 'University of Texas Austin': 'UT Austin', 'Florida': 'University of Florida', 'Geneva': 'University of Geneva', 'Hawaii': 'University of Hawaii', 'Maryland': 'University of Maryland', 'Michigan': 'University of Michigan', 'Minnesota': 'University of Minnesota', 'Sheffield': 'University of Sheffield', 'Victoria': 'University of Victoria', 'Virginia': 'University of Virginia', 'Washington': 'University of Washington', 'University of Wisconsin Madison': 'UW Madison', 'Wisconsin': 'UW Madison', 'UW': 'UW Madison', 'UW-Madison': 'UW Madison'} Uni_name_ambiguity.keys() dfk = dfk.replace({'Affiliation': Uni_name_ambiguity}) dfk = dfk.groupby(['Applicant', 'Affiliation'])['Attempts'].sum().reset_index() return dfk  Applicant stats Extracting tables for applicant job performance (along with their latest affiliation at the time of job application) from tables for job results.\nApplicantTable = {} for i in range(2005, 2020): attempt = df[i]['Short List'].str.split(\u0026quot;\\)\u0026quot;, expand=True) attempt = attempt.unstack() attempt = attempt.str.split(r\u0026quot;\\[.*?\\]\u0026quot;).str.join('') attempt = attempt.str.strip() attempt = attempt.value_counts() attempt = attempt.to_frame() attempt.reset_index(level=0, inplace=True) attempt.columns = ['Applicant', 'Attempts'] attemptTable = attempt['Applicant'].str.split('(', expand=True) attemptTable.columns = ['Applicant', 'Affiliation'] attemptTable['Attempts'] = attempt['Attempts'] attemptTable = attemptTable.iloc[1:] indexDrop = attemptTable[attemptTable['Applicant'].str.contains(\u0026quot;\\)\u0026quot; or \u0026quot;\\(\u0026quot; or \u0026quot;[\u0026quot; or \u0026quot;]\u0026quot;)].index attemptTable.drop(indexDrop , inplace=True) attemptTable.Affiliation.str.strip() attemptTable = UniNameAmbiguityFix(attemptTable) offerTable = df[i]['Offers'].str.split(r\u0026quot;\\(.*?\\)\u0026quot;, expand=True) offerTable = offerTable.unstack() offerTable = offerTable.str.strip() offerTable = offerTable.value_counts() offerTable = offerTable.to_frame() offerTable.reset_index(level=0, inplace=True) offerTable.columns = ['Applicant', 'Offers'] offerTable['Applicant'] = offerTable['Applicant'].str.replace(u'† \\xa0', u'') offerTable = offerTable.iloc[1:] attemptTable.Applicant = attemptTable.Applicant.str.strip() offerTable.Applicant = offerTable.Applicant.str.strip() ApplicantTable[i] = attemptTable.merge(offerTable, how='left', left_on='Applicant', right_on='Applicant') ApplicantTable[i] = ApplicantTable[i].fillna(0) ApplicantTable[i].Offers = ApplicantTable[i].Offers.astype(int) #applicants with no affiliations listed are dropped ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Affiliation'].str.strip() == \u0026quot;\u0026quot;].index , inplace=True) #blank applicant dropped ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Applicant'].str.strip() == \u0026quot;\u0026quot;].index , inplace=True) #theory or non-hep jobs to be dropped ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Applicant'].str.lower().str.contains('theory')].index , inplace=True) ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Applicant'].str.lower().str.contains('hep')].index , inplace=True) ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Affiliation'] == 'IAS'].index , inplace=True) ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Affiliation'] == 'theory'].index , inplace=True) #other misc. cleaning ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Affiliation'] == 'notes below'].index , inplace=True) ApplicantTable[i].drop(ApplicantTable[i][ApplicantTable[i]['Affiliation'] == 'Ultralytics'].index , inplace=True) ApplicantTable[i] = ApplicantTable[i].sort_values(by=['Offers', 'Attempts'], ascending=False) ApplicantTable[i]  ApplicantTable[2015].head()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Applicant Affiliation Attempts Offers     67 Joshua Spitz MIT 7 2   5 Alex Himmel Duke 5 2   77 Laura Fields Northwestern 4 2   90 Matt Wetstein UChicago 4 2   12 Andrzej Szelc Yale 2 2     Combining data of all the years. I define a success as getting at least one job offer, ie assign an applicant success = 1. With no offers at all, I define the (short-listed) candidate to be unsuccessful, ie assign the applicant success = 0.\nApplicantTableAllYears = pd.concat(ApplicantTable, ignore_index=True) ApplicantTableAllYears = ApplicantTableAllYears.groupby(['Applicant', 'Affiliation'])['Attempts', 'Offers'].sum().reset_index() ApplicantTableAllYears = ApplicantTableAllYears.sort_values(by=['Offers', 'Attempts'], ascending=False) ApplicantTableAllYears['Success'] = (ApplicantTableAllYears['Offers'] \u0026gt; 0).astype(int) ApplicantTableAllYears   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Applicant Affiliation Attempts Offers Success     219 Florencia Canelli FNAL 15 7 1   570 Sabine Lammers Columbia 7 5 1   85 Ben Kilminster Ohio State 8 4 1   114 Carter Hall SLAC 5 4 1   214 Eva Halkiadakis Rochester 9 3 1   ... ... ... ... ... ...   678 Yoshikazu Nagai UC Boulder 1 0 0   683 Yusuke Koshio University of Tokyo 1 0 0   685 Zarko Pavlovic LANL 1 0 0   687 Zeynep Demeragli MIT 1 0 0   689 Zhengyun You UC Irvine 1 0 0    693 rows × 5 columns\n How to rank University/lab (employing postdocs) in terms of their postdocs success? To assess the average quality of postdocs in an organization (affiliation), I add a Offers/candidate metric. Total offers also give an estimate of the success of the affiliation. I use these two university metrics to rank the universities/labs to produce successful candidates affiliated to them (first priority given to Total Offers, and then to Offers/candidate).\nUniversityTableAllYears = ApplicantTableAllYears.drop(columns=['Applicant', 'Attempts']) UniversityTableAllYears['Failure'] = (UniversityTableAllYears['Offers'] == 0).astype(int) UniversityTableAllYears = UniversityTableAllYears.groupby(['Affiliation'])['Offers', 'Success', 'Failure'].sum().reset_index() UniversityTableAllYears['Offers/candidate'] = UniversityTableAllYears['Offers']*1./(UniversityTableAllYears['Success'] + UniversityTableAllYears['Failure']) UniversityTableAllYears.columns = ['Affiliation', 'Total Offers', 'Total successful candidates', 'Total unsuccessful candidates', 'Offers/candidate'] UniversityTableAllYears = UniversityTableAllYears.sort_values(by=['Total successful candidates', 'Offers/candidate'], ascending=False) UniversityTableAllYears['Rank'] = np.arange(1,150) UniversityTableAllYears   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Affiliation Total Offers Total successful candidates Total unsuccessful candidates Offers/candidate Rank     32 FNAL 58 39 26 0.892308 1   56 LBNL 23 20 12 0.718750 2   120 UChicago 25 17 10 0.925926 3   15 CERN 16 15 29 0.363636 4   24 Columbia 19 12 3 1.266667 5   ... ... ... ... ... ... ...   138 University of Sussex 0 0 1 0.000000 145   139 University of Tokyo 0 0 1 0.000000 146   140 University of Victoria 0 0 2 0.000000 147   145 Western Illinois 0 0 1 0.000000 148   146 William and Mary 0 0 1 0.000000 149    149 rows × 6 columns\n Candidates with at least one offer are counted as successful, while ones with no offer are counted as unsuccessful candidates.\nData visualization plt.style.use('ggplot') x_pos = [i for i, _ in enumerate(UniversityTableAllYears['Affiliation'].iloc[:5])] plt.bar(x_pos, UniversityTableAllYears['Total successful candidates'].iloc[:5], color='green') plt.xlabel(\u0026quot;Postdoc affiliation\u0026quot;) plt.ylabel(\u0026quot;Total successful candidates\u0026quot;) plt.title(\u0026quot;Best 5 postdoc affiliations which produced largest number of successful candidates (from 2005-2019)\u0026quot;) plt.xticks(x_pos, UniversityTableAllYears['Affiliation'].iloc[:5]) plt.show()  UniversityTableAllYearsBestOfferRate = UniversityTableAllYears.sort_values(by=['Offers/candidate'], ascending=False) plt.style.use('ggplot') x_pos = [i for i, _ in enumerate(UniversityTableAllYearsBestOfferRate['Affiliation'].iloc[:5])] plt.bar(x_pos, UniversityTableAllYearsBestOfferRate['Offers/candidate'].iloc[:5], color='green') plt.xlabel(\u0026quot;Postdoc affiliation\u0026quot;) plt.ylabel(\u0026quot;Avg. offer per candidate\u0026quot;) plt.title(\u0026quot;Best 5 postdoc affiliations which have highest offers per candidate (from 2005-2019)\u0026quot;) plt.xticks(x_pos, UniversityTableAllYearsBestOfferRate['Affiliation'].iloc[:5]) plt.show()  Success of postdocs w.r.t their affiliation\u0026rsquo;s (university/lab\u0026rsquo;s) metrics In addition to the binary metric of at least one offer as success, I add another candidate metric - Success odds. Success odds = (total offers)/(total attempts - total offers) for a candidate. The correlation between candidate metrics and university/lab (affiliation) metrics is of interest, as it gives an intuition about the spead of department\u0026rsquo;s success metrics over its postdocs. Are there some good/bad postdocs who skew their affiliation\u0026rsquo;s (university\u0026rsquo;s) success metric or are all the postdocs in general doing similarly from that university in academic job hunting.\nApplicantTableAllYearRanked = ApplicantTableAllYears.merge(UniversityTableAllYears[['Affiliation', 'Rank', 'Offers/candidate', 'Total successful candidates', 'Total unsuccessful candidates']], how='left', left_on='Affiliation', right_on='Affiliation') ApplicantTableAllYearRanked.rename(columns={'Rank':'Affiliation rank'}, inplace=True) ApplicantTableAllYearRanked['Success odds'] = ApplicantTableAllYearRanked['Offers']/(ApplicantTableAllYearRanked['Attempts'] - ApplicantTableAllYearRanked['Offers']) ApplicantTableAllYearRanked   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Applicant Affiliation Attempts Offers Success Affiliation rank Offers/candidate Total successful candidates Total unsuccessful candidates Success odds     0 Florencia Canelli FNAL 15 7 1 1 0.892308 39 26 0.875   1 Sabine Lammers Columbia 7 5 1 5 1.266667 12 3 2.500   2 Ben Kilminster Ohio State 8 4 1 19 0.900000 4 6 1.000   3 Carter Hall SLAC 5 4 1 7 0.888889 9 9 4.000   4 Eva Halkiadakis Rochester 9 3 1 20 0.857143 4 3 0.500   ... ... ... ... ... ... ... ... ... ... ...   688 Yoshikazu Nagai UC Boulder 1 0 0 34 0.500000 3 3 0.000   689 Yusuke Koshio University of Tokyo 1 0 0 146 0.000000 0 1 0.000   690 Zarko Pavlovic LANL 1 0 0 22 0.666667 4 2 0.000   691 Zeynep Demeragli MIT 1 0 0 6 0.608696 12 11 0.000   692 Zhengyun You UC Irvine 1 0 0 139 0.000000 0 2 0.000    693 rows × 10 columns\n Success odds vs. Affiliation metric Pearson correlation:\ncorrelation = ApplicantTableAllYearRanked[['Offers/candidate' ,'Total successful candidates', 'Affiliation rank', 'Success odds']] correlation.corr()   .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }    Offers/candidate Total successful candidates Affiliation rank Success odds     Offers/candidate 1.000000 0.414271 -0.686715 0.341810   Total successful candidates 0.414271 1.000000 -0.588940 0.159448   Affiliation rank -0.686715 -0.588940 1.000000 -0.235494   Success odds 0.341810 0.159448 -0.235494 1.000000     Offer/candidate has a higher correlation with success odds.\n#Support Vector Regression from sklearn.svm import SVR, LinearSVR  Y = np.array(ApplicantTableAllYearRanked['Success odds'].astype(float)) Y = np.nan_to_num(Y)  plt.scatter(ApplicantTableAllYearRanked['Affiliation rank'], ApplicantTableAllYearRanked['Success odds'], alpha=0.5, color='blue', marker='.', label='data') plt.xlabel('Affiliation rank') plt.ylabel('Success odds') plt.xlim([-0.01,160]) plt.ylim([-0.01,4.5]) plt.legend() plt.show()  plt.scatter(ApplicantTableAllYearRanked['Total successful candidates'], ApplicantTableAllYearRanked['Success odds'], alpha=0.5, color='blue', marker='.', label='data') plt.xlabel('Total successful candidates') plt.ylabel('Success odds') plt.xlim([-1,40]) plt.ylim([-0.1,4.5]) plt.legend() plt.show()  plt.scatter(ApplicantTableAllYearRanked['Offers/candidate'], ApplicantTableAllYearRanked['Success odds'], alpha=0.5, color='blue', marker='.', label='data') plt.xlabel('Offers/candidate') plt.ylabel('Success odds') plt.xlim([-0.1,1.4]) plt.ylim([-0.1,4.5]) X = np.array(ApplicantTableAllYearRanked[['Offers/candidate']].astype(float)) X = np.nan_to_num(X) Z = np.array(ApplicantTableAllYearRanked[['Offers/candidate', 'Total successful candidates']].astype(float)) svr_linOfferDensity = LinearSVR(random_state=0, tol=1e-5) #svr_rbf = SVR(kernel='rbf', C=1e3, gamma=0.1) Y_svrlinOfferDensity = svr_linOfferDensity.fit(X, Y).predict(X) #Y_rbf = svr_rbf.fit(Z, Y).predict(Z) plt.plot(X, Y_svrlinOfferDensity, color='green', lw=1, label='Linear fit (only Offers/candidate)') #plt.plot(X, Y_rbf, color='black', lw=1, label='rbf model') plt.legend() plt.show()  /home/sourav/.local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:90: RuntimeWarning: overflow encountered in reduce return ufunc.reduce(obj, axis, dtype, out, **passkwargs)  Success vs. Affiliation metric ApplicantTableAllYearRanked.plot(x='Affiliation rank', y='Success', style='.', alpha = 0.2)  \u0026lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd76e2cc470\u0026gt;  ApplicantTableAllYearRanked.plot(x='Total successful candidates', y='Success', style='o', alpha = 0.1)  \u0026lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd76b992fd0\u0026gt;  t = ApplicantTableAllYearRanked[['Total successful candidates', 'Success']] t = t.sort_values(by=['Total successful candidates'], ascending=False) tsuccess = t[t['Success'] == 1] tfailure = t[t['Success'] == 0] bins=3 plt.hist(tsuccess['Total successful candidates'], bins, alpha=0.3, label='Success') plt.hist(tfailure['Total successful candidates'], bins, alpha=0.3, label='Failure') plt.xlabel('Total successful candidates') plt.ylabel('frequency') plt.legend(loc='best') plt.show()  ApplicantTableAllYearRanked.plot(x='Offers/candidate', y='Success', style='.', alpha = 0.2)  \u0026lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd76b9c8438\u0026gt;  t = ApplicantTableAllYearRanked[['Offers/candidate', 'Success']] t = t.sort_values(by=['Offers/candidate'], ascending=False) tsuccess = t[t['Success'] == 1] tfailure = t[t['Success'] == 0] bins=3 plt.hist(tsuccess['Offers/candidate'], bins, alpha=0.3, label='Success') plt.hist(tfailure['Offers/candidate'], bins, alpha=0.3, label='Failure') plt.xlabel('Offers/candidate') plt.ylabel('frequency') plt.legend(loc='best') plt.show()  Offer/candidate has a fair discriminating power between success and failure cases.\nlogisticRegr = LogisticRegression() logisticRegr.fit(ApplicantTableAllYearRanked[['Affiliation rank']], ApplicantTableAllYearRanked['Success']) logisticRegr.score(ApplicantTableAllYearRanked[['Affiliation rank']], ApplicantTableAllYearRanked['Success'])  /home/sourav/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) 0.5844155844155844  logisticRegr = LogisticRegression() logisticRegr.fit(ApplicantTableAllYearRanked[['Affiliation rank', 'Offers/candidate', 'Total successful candidates']], ApplicantTableAllYearRanked['Success']) logisticRegr.score(ApplicantTableAllYearRanked[['Affiliation rank', 'Offers/candidate', 'Total successful candidates']], ApplicantTableAllYearRanked['Success'])  /home/sourav/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) 0.6536796536796536  logisticRegr = LogisticRegression() logisticRegr.fit(ApplicantTableAllYearRanked[['Total successful candidates']], ApplicantTableAllYearRanked['Success']) logisticRegr.score(ApplicantTableAllYearRanked[['Total successful candidates']], ApplicantTableAllYearRanked['Success'])  /home/sourav/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) 0.5526695526695526  logisticRegr = LogisticRegression() logisticRegr.fit(ApplicantTableAllYearRanked[['Total successful candidates', 'Offers/candidate']], ApplicantTableAllYearRanked['Success']) logisticRegr.score(ApplicantTableAllYearRanked[['Total successful candidates', 'Offers/candidate']], ApplicantTableAllYearRanked['Success'])  /home/sourav/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) 0.6551226551226551  logisticRegr = LogisticRegression() logisticRegr.fit(ApplicantTableAllYearRanked[['Offers/candidate']], ApplicantTableAllYearRanked['Success']) logisticRegr.score(ApplicantTableAllYearRanked[['Offers/candidate']], ApplicantTableAllYearRanked['Success'])  /home/sourav/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning. FutureWarning) 0.6551226551226551  \u0026lsquo;Total successful candidates\u0026rsquo; metric does not provide any additional discriminating power than \u0026lsquo;Offers/candidate\u0026rsquo; metric.\nTo get an intuition of why \u0026lsquo;Offers/candidate\u0026rsquo; metric is a good indicator of postdoc success, let\u0026rsquo;s look at the actual distribution of number of offer of a hep-ex postdoc:\nApplicantTableAllYearRanked['Offers'].hist(bins=10)  \u0026lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd76b86f2b0\u0026gt;  Since most postdocs in hep-ex typically do not receive more than 1 offer, \u0026lsquo;Offers/candidate\u0026rsquo; (ie the avg. number of offers by a postdoc from a given afiliation (university/lab), actually represents the number of successful postdocs of that affiliation.\nSummary  Hence, \u0026lsquo;Offers/candidate\u0026rsquo; is the best metric to indicate if a university/lab produces successful postdocs. According to \u0026lsquo;Offers/candidate\u0026rsquo; metric Columbia University is the best university to do a hep-ex postdoc.  Next steps  temporal variations in hep-ex job market not taken into account US and non-US jobs to be treated separately should separate the study into energy, intensity and cosmic frontiers, as the job trends and funding are different for each think of other metrics  ","date":1570512430,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570512430,"objectID":"3150223a17d8a7a30b8717f0fbc34efb","permalink":"https://sen-sourav.github.io/project/postdocsuccess/","publishdate":"2019-10-08T01:27:10-04:00","relpermalink":"/project/postdocsuccess/","section":"project","summary":"%%HTML \u0026lt;style type=\u0026quot;text/css\u0026quot;\u0026gt; table.dataframe td, table.dataframe th { border: 1px black solid !important; color: black !important; } \u0026lt;/style\u0026gt;  table.dataframe td, table.dataframe th { border: 1px black solid !important; color: black !important; }  As an experimental High Energy Physics (hep-ex) grad student, I often wonder which university/national lab should I choose for doing a postdoc to increase my odds of getting a faculty position, if I plan to stay in academia.","tags":[],"title":"Postdoc Success Indicator","type":"project"},{"authors":[],"categories":[],"content":" The problem Below is a text transliterated in English:\n   \u0026ldquo;aaj ka mausam achchha hai\u0026rdquo; \u0026ldquo;The weather is good today\u0026rdquo;     (transliterated text) (translated text)    One might be curious about what language is this transliterated text actually in (unless one knows that language already). Happens to me quite often, when I\u0026rsquo;m reading Youtube or Facebook or other social media threads.\nWell, the above text is in Hindi:\n   \u0026ldquo;aaj ka mausam achchha hai\u0026rdquo; \u0026ldquo;आज का मौसम अच्छा है\u0026rdquo;     (transliterated text) (original script)    Since computer and phone keyboards are generally in English, it is often convenient for non-roman language speakers to transliterate their texts to English while typing than to use the original script (writing system) of their language. Since the transliterated text does not have the information about its original language, it becomes hard for others (who do not speak that language) to even decipher the language and further understand the meaning of the text.\nIt would be convenient if machines could fill this gap by telling us the language of those transliterated texts, which we very often encounter in social media threads etc., so that we don\u0026rsquo;t have to ask other people if they can identify the language of a transliterated text.\nScope of the project In this project, I therefore attempt to address this problem by designing an NLP model which can detect the language of a transliterated text. Due to lack of time at the moment, I confine the scope of this project to just classify texts transliterated from Korean and Bangla (Bengali) languages.\nAlthough not important, but the reason for choosing these two non-roman languages in particular for the project is because:\n* Bangla is my mother tongue so it would be fun to teach the machine my language. Bangla (or Bengali) is spoken mostly in the state of West Bengal in India and in Bangladesh. * Korean pop songs are popular lately, so considering their international reach, I thought, Korean transliteration might be relevant to people. * I shall be including other non-roman languages in the future.\nSolution approach We can often identify a language being spoken, if we have prior experience of hearing that language, even if we may not understand the language at all. Every language has some characteristic sounds patterns. These patterns can be used to identify a language even without understanding them. So, like speech, if we know the correct pronounciation of transliterated texts (ie pronounciation in their original langauge), we might be able to identify the language, given we have some prior familiarity with how the language generally sounds.\nAutomatic Speech Recognition (ASR) systems are pretty decent in identifying language from speech audio inputs. ASRs use spectrograms (shown below) to learn features of a speech input such as its language.\n[Image source: Kovitvongsa, Kathryn \u0026amp; Lobel, Phillip. (2019). Convenient Fish Acoustic Data Collection in the Digital Age.]\nIn spectrograms, audio files are chopped into thin time slices (in the abscissa), and for each time slice, all the frequencies present in it are plotted (in the ordinate) with their corresponding intensities are represented in the heat map, obtained using Fourier transform. The frequencies tell us about the nature of the source that produced that sound, e.g., you can identify musical instruments by the pattern of their overtones (multiples of fundamental frequency).\nSo, in spectrograms of human speech audio files, the frequencies in a particular time slice should indicate the part of buccal cavity that produced it. It would be ideal if one knew the time span of each characteristic sound that create the words in a language. However, since that is not known, in spectrograms, the time is sliced into very small intervals, so that the NLP model can join a few of those small time slices and learn the actual length of a particular characteristic sound.\nIf we could split our transliterated words into fragments which represent the characteristic sounds, a string of those word fragments would be analogous to spectrograms for audio speech. We can then use those word fragment strings as inputs to an NLP model to identify the language of the transliterated text.\nFortunately, when a text is transliterated from one langauge to other, it is generally spelled out phonetically (even if the original language is not strictly phonetic). So, if we were to phonetically pronounce the transliterated words, we might be quite closer to its actual pronounciation.\nTo get the phonetic pronounciation, we assumed that the texts were transliterated from some unknown language to Italian, a strictly phonetic language which also uses the Latin script as English. We then divide the transliterated words into syllables according to the Italian language, ie phonetically. We used those (phonetic) syllables as inputs to our NLP model.\nData scraping Song lyrics website often transliterate songs in English (perhaps for international audiences). So, for Korean and Bangla (Bengali) sentences transliterated in English, the song lyrics on the following lyrics websites were scraped: - bangla lyrics: http://www.lyricsbangla.com/ - korean lyrics: https://romanization.wordpress.com/\nfrom urllib.request import urlopen from bs4 import BeautifulSoup import re  Since the objects in Bengali (referred as Bangla henceforth) and Korean texts might be different created two separate functions to fetch respective text. The different functions are just for cleanliness purpose.\nFunctions for scraping Korean transliterated texts def fetch_korean(fname): #some browsing revealed there are 1087 pages (@29th July, 2019) indexed 0 through 1086 with links to lyrics #extracting the song links from each of these pages npages = 1087 lyricsbag = open(fname, 'w') count = 0 for pg in range(npages): soup = BeautifulSoup(urlopen(\u0026quot;https://romanization.wordpress.com/page/%i\u0026quot;%pg), 'html.parser') links = soup.find_all('a') pageurls = [_.get('href') for _ in links if (_.text == 'Continue reading →')] for url in pageurls: b = koreanLyrics(url) [lyricsbag.write(_+\u0026quot;\\n\u0026quot;) for _ in b] count += 1 print(count) return  def koreanLyrics(url): s = BeautifulSoup(urlopen(url), 'html.parser') lblob = [_.text for _ in s.find_all('p')] lyrics = [] pendown = False for _ in lblob: if pendown: if (_ == \u0026quot;//\u0026quot;): pendown = False break else: lyrics += _.split(\u0026quot;\\n\u0026quot;) else: if \u0026quot;to see the lyrics\u0026quot; in _: pendown = True return lyrics  Functions for scraping Bangla transliterated texts def fetch_bangla(fname): #url = \u0026quot;http://www.lyricsbangla.com/?sec=listing\u0026amp;lyricid=4140\u0026quot; url = \u0026quot;file:///home/sourav/MLProjects/transliterate/Lyrics%20Search%20»%20LyricsBangla.com.html\u0026quot; #TODO replace the static page with dynamic link smh #\u0026quot;http://www.lyricsbangla.com/index.php?sec=search\u0026quot; html = urlopen(url) soup = BeautifulSoup(html, 'html.parser') b = soup.find('table') urltable = b.find_all('td') #extracting songs from links in www.lyricsbangla.com index page lyricsurllist = [] lyricsbag = open(fname, 'w') count = 0 for u in urltable: if (u.find('a') != None): songlink = u.a.get('href') if (\u0026quot;artist\u0026quot; not in songlink): b = banglaLyrics(songlink) [lyricsbag.write(_+\u0026quot;\\n\u0026quot;) for _ in b] count += 1 print(count) return  Bangla lyrics often have chords, so here is a list of chords to clean the text scraped from: https://www.pianochord.org/ and saved in \u0026ldquo;chords.txt\u0026rdquo;\n##(source: https://www.pianochord.org/) def get_musicalchords(): chords_ = [] f = open(\u0026quot;chords.txt\u0026quot;, 'r') lines = f.readlines() for l in lines: chords_ += l.strip().split() return chords_  def banglaLyrics(url): spchar = re.compile('[@_!#$%^\u0026amp;*()\u0026lt;\u0026gt;?/\\|}{~:]') s = BeautifulSoup(urlopen(url), 'html.parser') lblob = s.find('p', id='tabs-1') lyrics = [] chord_ = get_musicalchords() for line in lblob: if (line.string != None): l = str(line) if any(chord in l for chord in chords_): continue elif (spchar.search(l)!=None): continue else: l = l.strip() if (l): lyrics.append(l) return lyrics  The following cell scrapes Bangla and Korean lyrics respectively using the functions defined above.\nbanglacorpus = \u0026quot;banglacorpus.txt\u0026quot; fetch_bangla(banglacorpus) koreancorpus = \u0026quot;koreancorpus.txt\u0026quot; fetch_korean(koreancorpus)  Data Cleaning \u0026ldquo;cleanedkoreancorpus.txt\u0026rdquo; and \u0026ldquo;cleanedbanglacorpus.txt\u0026rdquo; are the cleaned corpuses for Korean and Bangla transliterated text used for the analysis\n\"Cleaning is messy!!\" ~Anonymous  Data Visualization for encoding import numpy as np import matplotlib.pyplot as plt %matplotlib inline import random import pyphen  While transliteration, words are spelled phonetically. So, if one spells the transliterated word phonetically, one might actually get quite close to the actual pronounciation in its native language. If the transliterated words are, therefore, split into phonetic syllables, a list of those phonetic syllables could represent the pronounciation of that word and thus information about its native language. These phonetic syllables are quite analogous to phoneme sequences used in ASR (Automatic Speech Recognition).\nSince English is not a phonetic language, its syllables are not phonetic. However, with we try to split the word using a phonetic language, like Italian, then the syllables would indeed be phonetic.\nI use a python package - \u0026lsquo;pyphen\u0026rsquo; (https://pyphen.org) for such syllable splitting. This package provides an option to choose the language in which the user wants to split the word. As discussed above, I used Italian, a phonetic language, to split the word into syllables, so that I get phonetic syllables.\nThe function below splits the words phonetically (as in italian) into list of syllables using Pyphen:\ndef PhoneticWordSplit(word): dic = pyphen.Pyphen(lang='it_IT') splitword = dic.inserted(word) splitword = splitword.replace(\u0026quot;-\u0026quot;, \u0026quot; \u0026quot;) return splitword  The words split into phonetic syllables are stored in koreanwordbag.txt and banglawordbag.txt for Korean and Bangla resp. and used to train and test the langauge detection model.\ndef WordBagMaker(corpusfilename, label): f = open(corpusfilename, 'r') lines = f.readlines() import random worddict = [] for l in lines: words = l.split() #only words present in sentences used, not single word sentences if (len(words) \u0026lt; 2): continue for w in words: #words with digits not used and single letter words not used if (len(w) \u0026gt; 1) and w.isalpha(): worddict.append(PhoneticWordSplit(w) + \u0026quot; : \u0026quot; + label) #shuffle the list random.shuffle(worddict) return worddict for lang in ['korean', 'bangla']: fl = open(\u0026quot;%swordbag.txt\u0026quot;%lang, 'w') [fl.write(_+\u0026quot;\\n\u0026quot;) for _ in WordBagMaker(\u0026quot;cleaned%scorpus.txt\u0026quot;%lang, \u0026quot;K\u0026quot; if lang=='korean' else \u0026quot;B\u0026quot; )] fl.close()  datakor = open(\u0026quot;koreanwordbag.txt\u0026quot;, 'r').readlines() databan = open(\u0026quot;banglawordbag.txt\u0026quot;, 'r').readlines()  A quick feature visualization to see if simple features, like syllable count per word,have any discriminating power.\ndef getfeatures(langcorpus): syllables_per_word = [] letters_per_syllable = [] for d in langcorpus: splitword = d.split(\u0026quot; : \u0026quot;)[0].split(\u0026quot; \u0026quot;) syllables_per_word.append(len(splitword)) [letters_per_syllable.append(len(_)) for _ in splitword] return syllables_per_word, letters_per_syllable syllables_per_wordKOR, letters_per_syllableKOR = getfeatures(datakor) syllables_per_wordBAN, letters_per_syllableBAN = getfeatures(databan) syllables_per_word = np.concatenate((syllables_per_wordKOR,syllables_per_wordBAN), axis=0) letters_per_syllable = np.concatenate((letters_per_syllableKOR, letters_per_syllableBAN), axis=0)  binsSPW = [_ - 0.5 for _ in range(1,11)] plt.xticks(range(1,11)) plt.hist(syllables_per_word, binsSPW, alpha=0.3, label='both languages') plt.hist(syllables_per_wordKOR, binsSPW, alpha=0.3, label='Korean') plt.hist(syllables_per_wordBAN, binsSPW, alpha=0.3, label='Bangla') plt.xlabel('#syllables/word') plt.ylabel('frequency') plt.legend(loc='best') plt.show()  Bangla words mostly have 2 syllables, Korean words can have upto 5 syllables in a word. A 10 syllable vector should be enough to encode a word from either language.\nbinsLPS = [_ - 0.5 for _ in range(1,11)] plt.xticks(range(1,11)) plt.hist(letters_per_syllable, binsLPS, alpha=0.3, label='both languages') plt.hist(letters_per_syllableKOR, binsLPS, alpha=0.3, label='Korean') plt.hist(letters_per_syllableBAN, binsLPS, alpha=0.3, label='Bangla') plt.xlabel('#letters/syllables') plt.ylabel('frequency') plt.legend(loc='best') plt.show()  Most phonetic syllables have around 2 letters. Not a significant disciminator. Would therefore be fair to disregard the syllable length and just integer encode the syllables in both the corpuses.\nTraining data Using 50,000 (10,000) Bangla and Korean words each randomly from the corpuses for training (testing).\nNtrain = 50000 Ntest = 10000 random.shuffle(datakor) #korean random.shuffle(databan) #bangla TrainingVal_data = datakor[:Ntrain] + databan[:Ntrain] Testing_data = datakor[Ntrain:Ntrain+Ntest] + databan[Ntrain:Ntrain+Ntest] random.shuffle(TrainingVal_data) random.shuffle(Testing_data)  Word and label encoding from keras.preprocessing.text import hashing_trick from keras.preprocessing.sequence import pad_sequences  vocab_size = 30 v = ['in in in', 'kab bo', 'so kal'] encoded_docs = [hashing_trick(d, vocab_size, hash_function='md5') for d in v] encoded_docs v1 = ['in in bo'] encoded_docs1 = [hashing_trick(d, vocab_size, hash_function='md5') for d in v1] print(encoded_docs1) print(encoded_docs)  [[26, 26, 3]] [[26, 26, 26], [15, 3], [26, 15]]  from keras.models import Sequential from keras.layers import Dense, Embedding, LSTM from keras.regularizers import l2  def datalabel(dataset): '''function to label words 'K' or 'B' for Korean and Bangla resp. ''' wvec = [] lvec = [] for td in dataset: tw, tl = td.split(\u0026quot; : \u0026quot;) #One hot encoding: [1,0] : Bangla, [0,1] : Korean l = [1, 0] if tl.strip() == \u0026quot;B\u0026quot; else [0,1] wvec.append(tw) lvec.append(l) return wvec, np.array(lvec)  Pipeline to integer encode phonetic syllables and pad words to a max of 10 syllables:\ndef IntEncodeWords(wordlist): vocab_size = 200000 max_length = 10 #integer encoding the syllables encoded_words = [hashing_trick(d, vocab_size, hash_function='md5') for d in wordlist] #padding to a max length of 10 padded_words = pad_sequences(encoded_words, maxlen=max_length, padding='post') return padded_words  Processing the training and testing data with the above pipeline\n#training data wordvec, labelvec = datalabel(TrainingVal_data) print(wordvec[:3]) print(labelvec[:3]) padded_docs = IntEncodeWords(wordvec) #testing data wordvec_test, labelvec_test = datalabel(Testing_data) padded_docs_test = IntEncodeWords(wordvec_test) print(wordvec_test[:5]) print(encoded_docs_test[:5])  ['nal', 'mi chyeo ga na b wa', 'ai'] [[0 1] [0 1] [0 1]] ['jeil', 'sa ran ghaeoh', 'sa ran ghae', 'aka sh', 'dal la jyeos seo'] [[55208], [67026, 161580, 152147], [67026, 161580, 25207], [48363, 63007], [9265, 18646, 109198, 141814]]  I train an LSTM to classify Korean and Bangla words, defined below:\nlstm_out = 5 # define the model model = Sequential() model.add(Embedding(vocab_size, 8, input_length=max_length)) model.add(LSTM(lstm_out, recurrent_initializer=\u0026quot;random_uniform\u0026quot;, bias_initializer=\u0026quot;zeros\u0026quot;, dropout=0.2, recurrent_dropout=0.2, kernel_regularizer=l2(0.01), recurrent_regularizer=l2(0.01), bias_regularizer=l2(0.01))) model.add(Dense(2, activation='softmax')) # compile the model model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # summarize the model print(model.summary())  Model: \u0026quot;sequential_5\u0026quot; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_5 (Embedding) (None, 10, 8) 1600000 _________________________________________________________________ lstm_5 (LSTM) (None, 5) 280 _________________________________________________________________ dense_5 (Dense) (None, 2) 12 ================================================================= Total params: 1,600,292 Trainable params: 1,600,292 Non-trainable params: 0 _________________________________________________________________ None  Early stopping the training if validation loss starts to converge (wait for 50 epochs to make sure validation loss is indeed converging).\nfrom keras.callbacks import EarlyStopping class ThresholdEarlyStopping(EarlyStopping): def __init__(self, monitor='val_loss', min_epochs=10, threshold=0.995, increase=1.75, verbose=0, mode='auto'): super(ThresholdEarlyStopping, self).__init__( monitor=monitor, patience=min_epochs, verbose=verbose, mode=mode ) self.threshold = threshold self.increase = increase def on_epoch_end(self, epoch, logs={}): if epoch \u0026lt; self.patience: current = logs.get(self.monitor) if current is None: warnings.warn('Early stopping requires %s to be available!' % (self.monitor), RuntimeWarning) if self.monitor_op(current, self.best): # if current val_loss within 0.5% margin of the best(min) val_loss, # add some grace to the patience to monitor if val_loss is indeed converging if self.monitor_op(current, self.threshold*self.best): self.patience = max(self.patience, epoch*self.increase) self.best = current else: if self.verbose \u0026gt; 0: print('Epoch %05d: early stopping' % (epoch)) self.model.stop_training = True  # fit the model print(labelvec[:5]) history = model.fit(padded_docs, labelvec, batch_size=2000, validation_split=0.1, epochs=500, verbose=1, callbacks=[ThresholdEarlyStopping(verbose=1, min_epochs=50)])  [[0 1] [0 1] [0 1] [1 0] [0 1]] Train on 90000 samples, validate on 10000 samples Epoch 1/500 90000/90000 [==============================] - 3s 36us/step - loss: 0.8363 - acc: 0.5272 - val_loss: 0.8187 - val_acc: 0.5392 Epoch 2/500 90000/90000 [==============================] - 2s 20us/step - loss: 0.8040 - acc: 0.6119 - val_loss: 0.7891 - val_acc: 0.8677 Epoch 3/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.7690 - acc: 0.7265 - val_loss: 0.7366 - val_acc: 0.7410 Epoch 4/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.6231 - acc: 0.8391 - val_loss: 0.4600 - val_acc: 0.9033 Epoch 5/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.4186 - acc: 0.9046 - val_loss: 0.3429 - val_acc: 0.9264 Epoch 6/500 90000/90000 [==============================] - 3s 30us/step - loss: 0.3586 - acc: 0.9267 - val_loss: 0.3144 - val_acc: 0.9287 Epoch 7/500 90000/90000 [==============================] - 2s 26us/step - loss: 0.3318 - acc: 0.9333 - val_loss: 0.2973 - val_acc: 0.9321 Epoch 8/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.3141 - acc: 0.9364 - val_loss: 0.2852 - val_acc: 0.9333 Epoch 9/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.3016 - acc: 0.9381 - val_loss: 0.2767 - val_acc: 0.9336 Epoch 10/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2936 - acc: 0.9392 - val_loss: 0.2698 - val_acc: 0.9354 Epoch 11/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2847 - acc: 0.9410 - val_loss: 0.2642 - val_acc: 0.9349 Epoch 12/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2782 - acc: 0.9411 - val_loss: 0.2615 - val_acc: 0.9343 Epoch 13/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2735 - acc: 0.9414 - val_loss: 0.2561 - val_acc: 0.9346 Epoch 14/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2698 - acc: 0.9422 - val_loss: 0.2525 - val_acc: 0.9332 Epoch 15/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2660 - acc: 0.9426 - val_loss: 0.2496 - val_acc: 0.9342 Epoch 16/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2626 - acc: 0.9429 - val_loss: 0.2473 - val_acc: 0.9353 Epoch 17/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2595 - acc: 0.9429 - val_loss: 0.2447 - val_acc: 0.9358 Epoch 18/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2582 - acc: 0.9428 - val_loss: 0.2424 - val_acc: 0.9346 Epoch 19/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2557 - acc: 0.9430 - val_loss: 0.2407 - val_acc: 0.9351 Epoch 20/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2530 - acc: 0.9425 - val_loss: 0.2394 - val_acc: 0.9334 Epoch 21/500 90000/90000 [==============================] - 3s 28us/step - loss: 0.2517 - acc: 0.9434 - val_loss: 0.2382 - val_acc: 0.9358 Epoch 22/500 90000/90000 [==============================] - 3s 28us/step - loss: 0.2502 - acc: 0.9431 - val_loss: 0.2367 - val_acc: 0.9351 Epoch 23/500 90000/90000 [==============================] - 2s 26us/step - loss: 0.2499 - acc: 0.9436 - val_loss: 0.2349 - val_acc: 0.9355 Epoch 24/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2478 - acc: 0.9431 - val_loss: 0.2341 - val_acc: 0.9385 Epoch 25/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2460 - acc: 0.9430 - val_loss: 0.2333 - val_acc: 0.9337 Epoch 26/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2449 - acc: 0.9435 - val_loss: 0.2325 - val_acc: 0.9352 Epoch 27/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2443 - acc: 0.9425 - val_loss: 0.2313 - val_acc: 0.9344 Epoch 28/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2436 - acc: 0.9431 - val_loss: 0.2309 - val_acc: 0.9348 Epoch 29/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2417 - acc: 0.9433 - val_loss: 0.2297 - val_acc: 0.9352 Epoch 30/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2424 - acc: 0.9431 - val_loss: 0.2292 - val_acc: 0.9344 Epoch 31/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2394 - acc: 0.9435 - val_loss: 0.2287 - val_acc: 0.9346 Epoch 32/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2396 - acc: 0.9434 - val_loss: 0.2281 - val_acc: 0.9329 Epoch 33/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2399 - acc: 0.9428 - val_loss: 0.2281 - val_acc: 0.9358 Epoch 34/500 90000/90000 [==============================] - 2s 21us/step - loss: 0.2386 - acc: 0.9431 - val_loss: 0.2272 - val_acc: 0.9334 Epoch 35/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2372 - acc: 0.9433 - val_loss: 0.2266 - val_acc: 0.9349 Epoch 36/500 90000/90000 [==============================] - 3s 29us/step - loss: 0.2360 - acc: 0.9433 - val_loss: 0.2264 - val_acc: 0.9333 Epoch 37/500 90000/90000 [==============================] - 2s 25us/step - loss: 0.2360 - acc: 0.9437 - val_loss: 0.2255 - val_acc: 0.9351 Epoch 38/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2367 - acc: 0.9433 - val_loss: 0.2251 - val_acc: 0.9325 Epoch 39/500 90000/90000 [==============================] - 2s 25us/step - loss: 0.2343 - acc: 0.9430 - val_loss: 0.2243 - val_acc: 0.9336 Epoch 40/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2336 - acc: 0.9432 - val_loss: 0.2241 - val_acc: 0.9340 Epoch 41/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2333 - acc: 0.9434 - val_loss: 0.2234 - val_acc: 0.9332 Epoch 42/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2328 - acc: 0.9433 - val_loss: 0.2234 - val_acc: 0.9344 Epoch 43/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2331 - acc: 0.9435 - val_loss: 0.2225 - val_acc: 0.9347 Epoch 44/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2324 - acc: 0.9434 - val_loss: 0.2221 - val_acc: 0.9338 Epoch 45/500 90000/90000 [==============================] - 2s 27us/step - loss: 0.2316 - acc: 0.9430 - val_loss: 0.2216 - val_acc: 0.9331 Epoch 46/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2302 - acc: 0.9427 - val_loss: 0.2211 - val_acc: 0.9341 Epoch 47/500 90000/90000 [==============================] - 2s 22us/step - loss: 0.2310 - acc: 0.9423 - val_loss: 0.2208 - val_acc: 0.9339 Epoch 48/500 90000/90000 [==============================] - 2s 23us/step - loss: 0.2290 - acc: 0.9427 - val_loss: 0.2205 - val_acc: 0.9341 Epoch 49/500 90000/90000 [==============================] - 2s 25us/step - loss: 0.2302 - acc: 0.9424 - val_loss: 0.2200 - val_acc: 0.9337 Epoch 50/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2288 - acc: 0.9424 - val_loss: 0.2197 - val_acc: 0.9337 Epoch 51/500 90000/90000 [==============================] - 2s 24us/step - loss: 0.2282 - acc: 0.9430 - val_loss: 0.2195 - val_acc: 0.9349 Epoch 00050: early stopping  check for overfitting by comparing the validation loss with training loss:\nplt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.ylabel('loss') plt.xlabel('epoch') plt.legend(['training loss', 'validation loss'], loc='best') plt.show()  The model is trained.\nevaluating the LSTM language classifier with testing data (with default decision boundary = 0.5):\n# evaluate the model loss, accuracy = model.evaluate(padded_docs_test, labelvec_test, verbose=0) print('Accuracy: %.2f %%' % (accuracy*100))  Accuracy: 93.36 %  Optimizing the decision boundary of the LSTM classifier for best accuracy using ROC curve:\nfrom sklearn.metrics import roc_curve, auc labelvec_pred = model.predict(padded_docs_test) fpr, tpr, cut = roc_curve(labelvec_test.ravel(), labelvec_pred.ravel()) AUC = auc(fpr, tpr)  labelvec_pred[:5], labelvec_test[:5, 0]  (array([[0.00991759, 0.99008244], [0.1209347 , 0.8790653 ], [0.00542074, 0.9945793 ], [0.995492 , 0.00450803], [0.00368168, 0.99631834]], dtype=float32), array([0, 0, 0, 1, 0]))  plt.figure(1) plt.plot([0, 1], [0, 1], 'k--') plt.plot(fpr, tpr, label='(AUC = {:.3f})'.format(AUC)) plt.xlabel('False positive rate') plt.ylabel('True positive rate') plt.title('ROC curve') plt.legend(loc='best') plt.show()  Closest point to (0,1) on the ROC above will have the optimal threshold (which reduces error conributed from both type I and II errors):\ntprDist = np.square(tpr-1) fprDist = np.square(fpr) DistFromPerfectEff = tprDist + fprDist Optimum_cut = cut[DistFromPerfectEff.argmin()] Optimum_cut  0.4986838  Optimal threshold at 0.5 (default cut for accuracy).\nStoring the model from keras.models import model_from_json #model to json model_json = model.to_json() json_file = open(\u0026quot;translit.json\u0026quot;, \u0026quot;w\u0026quot;) json_file.write(model_json) #weights to h5 model.save_weights(\u0026quot;translit.h5\u0026quot;) print(\u0026quot;model saved to disk\u0026quot;)  model saved to disk  Loading the model # load model jfile = open('translit.json', 'r') loaded_model_json = jfile.read() jfile.close() loaded_model = model_from_json(loaded_model_json) # load weights loaded_model.load_weights(\u0026quot;translit.h5\u0026quot;) print(\u0026quot;Loaded model from disk\u0026quot;) # compile the loaded model loaded_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  Loaded model from disk  The loaded model reproduces the accuracy for transliterated words:\n# evaluate the loaded model loaded_loss, loaded_accuracy = loaded_model.evaluate(padded_docs_test, labelvec_test, verbose=0) print('Accuracy: %.2f %%' % (loaded_accuracy*100))  Accuracy: 93.36 %  Using Maximum Likelihood Estimator to predict the language of an entire transliterated sentence, from the individual scores of the words in that sentence:\n$$Prediced\\ Language = \\underset{l}{\\operatorname{argmax}} \\sum{i=1}^{all\\ words\\ in\\ sentence} log(P(word{i}|l))$$\nwhere $l \\in { Korean, Bengali } $\nand $P(word|l)$ is output score of the word from the LSTM classifier for language $l$\nimport string def TextToInput(text): text = text.translate(str.maketrans('', '', string.punctuation)).split() text = [PhoneticWordSplit(w) for w in text] return IntEncodeWords(text)  def PredictLanguage(text): lstminput = TextToInput(text) p = model.predict(lstminput) langdict = {0:\u0026quot;Bengali\u0026quot;, 1:\u0026quot;Korean\u0026quot;} mle = np.log(p) mle = np.sum(mle, axis=0) return langdict[np.argmax(mle)]  inputtext = \u0026quot;cheoeumbuteo geudaeyeossjyo \\ naege dagaol han saram \\ dan han beonui seuchimedo \\ nae nunbicci mareul hajyo\u0026quot; #\u0026quot;Amake naam~ #ki?!@\u0026quot; PredictLanguage(inputtext)  'Korean'  Results The LSTM classifier using phonetic syllables as input features is able to give an optimum accuracy of ~93 % with AUC = 0.985.\nNext steps:  Create a web-app to run the NLP model and host on google cloud.\n Perform k-fold cross-validation to better estimate classifier\u0026rsquo;s performance\n Should test vanilla RNN too since the input string of phonetic syllables are not too long\n Improve cleaning to get rid of non-lexical vocables in the corpus to train a better discriminator\n Try to find other sources (than song lyrics) for Korean and Bangla transliterated texts\n Think of a better way to reduce even further English words that are contaminating the corpuses\n Add other non-roman langauges  ","date":1570512131,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1570512131,"objectID":"216e70431dc071ecb3b3c6601633db87","permalink":"https://sen-sourav.github.io/project/detecttransliterationlanguage/","publishdate":"2019-10-08T01:22:11-04:00","relpermalink":"/project/detecttransliterationlanguage/","section":"project","summary":"The problem Below is a text transliterated in English:\n   \u0026ldquo;aaj ka mausam achchha hai\u0026rdquo; \u0026ldquo;The weather is good today\u0026rdquo;     (transliterated text) (translated text)    One might be curious about what language is this transliterated text actually in (unless one knows that language already). Happens to me quite often, when I\u0026rsquo;m reading Youtube or Facebook or other social media threads.\nWell, the above text is in Hindi:","tags":[],"title":"Detect Language of Transliterated Texts","type":"project"},{"authors":["C. H. Yeh","S. V. Chekanov","A. V. Kotwal","J. Proudfoot","S. Sen","N. V. Tran","S. S. Yu"],"categories":null,"content":"","date":1556668800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1556668800,"objectID":"ef4d9a7b6045edfea2fe5e94190983e9","permalink":"https://sen-sourav.github.io/publication/yeh-2019/","publishdate":"2019-10-07T07:36:53.896782Z","relpermalink":"/publication/yeh-2019/","section":"publication","summary":"","tags":null,"title":"Studies of granularity of a hadronic calorimeter for tens-of-TeV jets at a 100 TeV pp collider","type":"publication"},{"authors":["Sourav Sen"],"categories":["Invited talk"],"content":"","date":1548201600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1548201600,"objectID":"f2d9b84e23cd2f23543a9422826c66bf","permalink":"https://sen-sourav.github.io/talk/pnp/","publishdate":"2019-01-23T00:00:00Z","relpermalink":"/talk/pnp/","section":"talk","summary":"","tags":null,"title":"Status of improvements in CTIDE Neural Networks","type":"talk"},{"authors":["ATLAS Collaboration"],"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1546300800,"objectID":"07e28fc8917062b6da47b94d54a13d1e","permalink":"https://sen-sourav.github.io/publication/2019508/","publishdate":"2019-10-07T07:36:53.895306Z","relpermalink":"/publication/2019508/","section":"publication","summary":"","tags":null,"title":"Measurements of gluon-gluon fusion and vector-boson fusion Higgs boson production cross-sections in the $H \u0026#8594; WW^* \u0026#8594; eν μν$ decay channel in pp collisions at  \u0026#8730;$s = $13TeV with the ATLAS detector","type":"publication"},{"authors":["C. H. Yeh","S. V. Chekanov","A. V. Kotwal","J. Proudfoot","S. Sen","N. V. Tran","S. S. Yu"],"categories":null,"content":"","date":1514764800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1514764800,"objectID":"2845d8a1ede55ae63de005b3713946a4","permalink":"https://sen-sourav.github.io/publication/yeh-2018-ujb/","publishdate":"2019-10-07T07:36:53.897679Z","relpermalink":"/publication/yeh-2018-ujb/","section":"publication","summary":"","tags":null,"title":"Jet Substructure Variables with the SiFCC Detector at 100 TeV","type":"publication"},{"authors":["Sourav Sen"],"categories":["Invited talk"],"content":"","date":1501113600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1501113600,"objectID":"61d6e6c7190b3d0c7ea81ec1c7ae6163","permalink":"https://sen-sourav.github.io/talk/usatlas17/","publishdate":"2017-07-27T00:00:00Z","relpermalink":"/talk/usatlas17/","section":"talk","summary":"","tags":null,"title":"Effects of reduced pixel charge information in ATLAS tracking","type":"talk"},{"authors":["Sourav Sen","Ashutosh Kotwal","Sergei Chekanov","Lindsey Gray","Nhan Tran","Shin-Shan Yu"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"87472beebff7520a01fb838f2c18f3a9","permalink":"https://sen-sourav.github.io/publication/sen-2017-detectors/","publishdate":"2019-10-07T07:36:53.895789Z","relpermalink":"/publication/sen-2017-detectors/","section":"publication","summary":"","tags":null,"title":"Detectors for Superboosted $τ $-leptons at Future Circular Colliders","type":"publication"},{"authors":["SV Chekanov","M Beydler","AV Kotwal","L Gray","S Sen","NV Tran","S-S Yu","J Zuzelski"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"b713a7693ddfcedfe86e840ed462eca4","permalink":"https://sen-sourav.github.io/publication/chekanov-2017-initial/","publishdate":"2019-10-07T07:36:53.896147Z","relpermalink":"/publication/chekanov-2017-initial/","section":"publication","summary":"","tags":null,"title":"Initial performance studies of a general-purpose detector for multi-TeV physics at a 100 TeV pp collider","type":"publication"},{"authors":["Shin-shan Yu","Sergei Chekanov","Lindsey Gray","Ashutosh Kotwal","Sourav Sen","Nhan Tran"],"categories":null,"content":"","date":1483228800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1483228800,"objectID":"ef54ec7fc35be967d75db94e2d3f1e78","permalink":"https://sen-sourav.github.io/publication/yu-2017-study/","publishdate":"2019-10-07T07:36:53.896516Z","relpermalink":"/publication/yu-2017-study/","section":"publication","summary":"","tags":null,"title":"Study Of Boosted W-Jets And Higgs-Jets With the SiFCCDetector","type":"publication"},{"authors":["Sourav Sen"],"categories":null,"content":"","date":1470441600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1470441600,"objectID":"246703d3f8974b4ad4514632df673b55","permalink":"https://sen-sourav.github.io/talk/ichep16/","publishdate":"2016-08-06T00:00:00Z","relpermalink":"/talk/ichep16/","section":"talk","summary":"","tags":null,"title":"Detectors for Superboosted tau-leptons at Future Circular Colliders","type":"talk"},{"authors":["Sourav Sen","Arnab K Ray"],"categories":null,"content":"","date":1388534400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1388534400,"objectID":"3c5170632d79154d308f3ad78ee7c9bb","permalink":"https://sen-sourav.github.io/publication/sen-2014-implications/","publishdate":"2019-10-07T07:36:53.897112Z","relpermalink":"/publication/sen-2014-implications/","section":"publication","summary":"","tags":null,"title":"Implications of nonlinearity for spherically symmetric accretion","type":"publication"},{"authors":["Barun Majumder","Sourav Sen"],"categories":null,"content":"","date":1325376000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1325376000,"objectID":"95208fabaa1212fdb0b2744fd1d46f49","permalink":"https://sen-sourav.github.io/publication/majumder-2012-modified/","publishdate":"2019-10-07T07:36:53.897406Z","relpermalink":"/publication/majumder-2012-modified/","section":"publication","summary":"","tags":null,"title":"Do the modified uncertainty principle and polymer quantization predict same physics?","type":"publication"}]